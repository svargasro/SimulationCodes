{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **How to run a CUDA code on GOOGLE COLAB**\n"
      ],
      "metadata": {
        "id": "Ee9N2kQVIFOg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. In the execution menu choice the GPU acceleration option"
      ],
      "metadata": {
        "id": "1_bJW-shHihz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. The next lines verify if a GPU was assigned"
      ],
      "metadata": {
        "id": "wcRKElN6IWd7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show if a CUDA Toolkit was installed\n",
        "!ls /usr/local\n",
        "# Show it the  nvcc command can be called\n",
        "!which nvcc\n",
        "# Show which NVIDIA card was assigned\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRiBwgEGnuk9",
        "outputId": "1e5a5790-dd0b-4923-d30f-99730c4c8020"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bin    cuda\tcuda-11.8  games\t       include\tlib64\t   man\t share\n",
            "colab  cuda-11\tetc\t   _gcs_config_ops.so  lib\tlicensing  sbin  src\n",
            "/usr/local/cuda/bin/nvcc\n",
            "Mon Jul 24 13:52:57 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Just paste your code below the line\n",
        "%%writefile RunCode.cu"
      ],
      "metadata": {
        "id": "T4u00TajKV1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Escribe el archivo .cu que se vaya a utilizar\n",
        "\n",
        "%%writefile RunCode.cu\n",
        "\n",
        "// Adding two vectors (c=a+b) on CUDA\n",
        "#include <iostream>\n",
        "#include <fstream>\n",
        "#include <cmath>\n",
        "using namespace std;\n",
        "\n",
        "#define Lx 16\n",
        "#define Nx 8\n",
        "const int Mx=(Lx+Nx-1)/Nx;\n",
        "\n",
        "//--------------------KERNELS----------------\n",
        "__global__ void AddVectors(float *d_a,float *d_b,float *d_c){\n",
        " //Which thread should I do?\n",
        "  int ix;  ix=blockIdx.x*blockDim.x+threadIdx.x;\n",
        "  d_c[ix]=d_a[ix]+d_b[ix];}\n",
        "\n",
        "\n",
        "int main(void){\n",
        "  int ix;\n",
        "  //DECLARE\n",
        "  //Declare arrays in the Host\n",
        "  float h_a[Lx],h_b[Lx],h_c[Lx];\n",
        "  //Declare arrays in the Device\n",
        "  float*d_a; cudaMalloc((void**) &d_a,Lx*sizeof(float));\n",
        "  float*d_b; cudaMalloc((void**) &d_b,Lx*sizeof(float));\n",
        "  float*d_c; cudaMalloc((void**) &d_c,Lx*sizeof(float));\n",
        "\n",
        "  //INPUT DATA\n",
        "  //Set data in the Host\n",
        "  for(ix=0;ix<Lx;ix++){\n",
        "    h_a[ix]=ix; h_b[ix]=2*ix;}\n",
        "\n",
        "  //Send data to the Device\n",
        "  cudaMemcpy(d_a,h_a,Lx*sizeof(float),cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(d_b,h_b,Lx*sizeof(float),cudaMemcpyHostToDevice);\n",
        "\n",
        "  //PROCESS\n",
        "  //Run parallel on the Device\n",
        "  dim3 ThreadsPerBlock(Nx,1,1);\n",
        "  dim3 BlocksPerGrid(Mx,1,1);\n",
        "  AddVectors<<<BlocksPerGrid,ThreadsPerBlock>>>(d_a,d_b,d_c);\n",
        "\n",
        "  //SHOW RESULTS\n",
        "  //Bring back to the Host\n",
        "  cudaMemcpy(h_c,d_c,Lx*sizeof(float),cudaMemcpyDeviceToHost);\n",
        "  for(ix=0;ix<Lx;ix++)\n",
        "    cout<<ix<<\" \"<<h_c[ix]<<endl;\n",
        "\n",
        "  //Free dynamic memory\n",
        "  cudaFree(d_a);  cudaFree(d_b);  cudaFree(d_c);\n",
        "\n",
        "  return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2b3ZpTdoTCo",
        "outputId": "6faa401c-7c0e-4ae9-a56a-afa60f8bbd2b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing RunCode.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Let us compile the .cu code with nvcc\n",
        "\n",
        "Notes:\n",
        "*   The flags are necessary if the GPU is a NVIDIA K80 card.\n",
        "*   The output archive \"Waves_CUDA.dat\" will appear in the directory on the left"
      ],
      "metadata": {
        "id": "8T6L-QHNKktA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compila el archivo .cu. La bandera es necesaria si usa una tarjeta Tesla K80\n",
        "!nvcc -arch=sm_37 -gencode=arch=compute_37,code=sm_37 RunCode.cu -o Ejecutar\n",
        "!./Ejecutar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkuFP1vLK3l3",
        "outputId": "80818176-e2fc-46c9-beae-2fdf5a644044"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc warning : The 'compute_35', 'compute_37', 'sm_35', and 'sm_37' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "0 0\n",
            "1 3\n",
            "2 6\n",
            "3 9\n",
            "4 12\n",
            "5 15\n",
            "6 18\n",
            "7 21\n",
            "8 24\n",
            "9 27\n",
            "10 30\n",
            "11 33\n",
            "12 36\n",
            "13 39\n",
            "14 42\n",
            "15 45\n"
          ]
        }
      ]
    }
  ]
}